---
title: "The impact of PEPFAR on UHSC - diff-in-diff analysis"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
lead: Melaku Dessie
---
## Overview 

### Background 
XX

Problem Statement: XX

Primary Research Question: XX
Supporting Research Questions:  

XXX


What are other predictors for better UHSC?

Implication: XXX....


### 
**The response variable is:**  
$Y$ (hsc): Universal Health Service Coverage Index 

**Other response variables for additional analysis are :**  
$Y$ (XXX):HSC Index - ID
$Y$ (XX): HSC Index- cap index

  
**The predicting variables are:**  

$X_2$ (gdppc ):GDP per capita ( current US $)
$X_3$ (govet):Government effectiveness estimate,
$X_4$ (gghe_d ):Domestic general government health expenditure (% of general government expenditure) , WHO
$X_5$ (pfunding): funding received from PEPFAR in USD 1000 for 2021 
$X_6$ (nodac):Net official development assistance received till 2020:  in XXXX https://data.worldbank.org/indicator/DT.ODA.ODAT.CD
$X_7$ (ehe):External health expenditure per capita, PPP(current international $) for 2020.https://data.worldbank.org/indicator/SH.XPD.EHEX.PP.CD?view=chart 

$X_9$ (pepfar):PEPFAR supported country( Yes, No) in 2021 in 1000
$X_10$ (incomeg ): world bank income group country classification for 2021 : low income and low-middle income.
$X_11$ (region ): region where is the country located based on the world bank classification 


***


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

### Loading packages

```{r}

library(scales)
library(ggplot2)
library(caret)
library(e1071)
library(magrittr)
library(partykit)
library(dplyr)
library(magrittr)
library(party)
library(MLmetrics)
library(mlr)
library(Metrics)
library(knitr)

```

### Data Loading 

```{r}

data <- read.csv('hsc_data_final_2024-01-18.csv', header = T)

variable.names(data)
```

### Preparing the Data and exploration

```{r}
# Remove the irrelevant columns
df<- data[-c(1,2,5,8,10,14,15,16)]
variable.names(df)

# Show the number of observations
obs = nrow(df)
cat("There are", obs, "observations in the data")
dim(df) # of variables/columns  

```

```{r}
# Convert the numerical and categorical variables to predictors
df$country = as.factor(df$country)
df$time_period = as.factor(df$time_period)
df$year = as.factor(df$year)
df$time_period = as.factor(df$time_period)
df$pepfar = as.factor(df$pepfar)
df$wb_2022_income_group = as.factor(df$wb_2022_income_group)

df$id= as.numeric(df$id)
df$service_cap= as.numeric(df$service_cap)
df$hsc= as.numeric(df$hsc)
df$gdppc_const_2015= as.numeric(df$gdppc_const_2015)
df$gov_effectiveness = as.numeric(df$gov_effectiveness)
df$net_official_development_assitance_const_2020= as.numeric(df$net_official_development_assitance_const_2020)
df$gghed = as.numeric(df$gghed)
df$pepfar_budget = as.numeric(df$pepfar_budget)
df$ext_health_exp = as.numeric(df$ext_health_exp)
str(df)
```

```{r}

table(df$region)

```

```{r}
# keep only the income group needed for this analysis 
df_hsc <- df %>%
  filter(region=="Sub-Saharan Africa"  )

# Check  NA -missing values for each column  
colSums(is.na(df_hsc))
head(df_hsc)
```

```{r}
# data imputation for missing values
df_imp<- df_hsc %>% 
   group_by(country) %>%
   mutate(
     gov_effectiveness_imputed=ifelse(is.na(gov_effectiveness), mean( gov_effectiveness, na.rm=TRUE),  gov_effectiveness),
     gdppc_const_2015_imputed=ifelse(is.na(gdppc_const_2015), mean(gdppc_const_2015, na.rm=TRUE),  gdppc_const_2015),
     net_official_development_assitance_const_2020_imputed =ifelse(is.na( net_official_development_assitance_const_2020 ), mean( net_official_development_assitance_const_2020, na.rm=TRUE),  net_official_development_assitance_const_2020 ),
     ext_health_exp_imputed =ifelse(is.na(ext_health_exp), mean(ext_health_exp, na.rm=TRUE),   ext_health_exp),
     gghed_imputed =ifelse(is.na( gghed), mean(gghed, na.rm=TRUE),gghed)
   )

df_imp$pepfar_budget_imputed <- ifelse(is.na(df_imp$pepfar_budget),0,df_imp$pepfar_budget)
```

```{r}
# check na valuea 
colSums(is.na(df_imp))

```


### Exploratory Data Analysis (EDA)
```{r}
# Set colors
gtblue = rgb(0, 48, 87, maxColorValue = 255)
techgold = rgb(179, 163, 105, maxColorValue = 255)
buzzgold = rgb(234, 170, 0, maxColorValue = 255)
bobbyjones = rgb(55, 113, 23, maxColorValue = 255)

# Check the distribution of the response, hsc
hist(df_imp$hsc,
     main="",
     xlab=" Distibution of hsc",
     border=buzzgold,
     col=gtblue)

```
HSC has a normal distribution and it's close symmetric.

```{r}
variable.names(df_imp)
```

```{r}
# Keep only variables we need


df_imp_hsc <- df_imp[-c(3,4,6,7,8,11,13,14)]
variable.names(df_imp_hsc)

```
```{r}

df_imp_hsc_clean <- df_imp_hsc[complete.cases(df_imp_hsc), ]

colSums(is.na(df_imp_hsc))
```
# Propensity Score Matching (PSM) is a method to create comparable countries 

```{r}
# Load the MatchIt package

library(MatchIt)

# Assuming 'data' is your dataset and 'treatment' is the treatment indicator variable
model_ps <- glm(pepfar ~ gov_effectiveness_imputed+ gghed_imputed+gdppc_const_2015_imputed, data = df_imp_hsc_clean, family = "binomial")

propensity_scores <- predict(model_ps, type = "response")

# Create a MatchIt object
matchit_object <- matchit(pepfar ~ gov_effectiveness_imputed+ gghed_imputed+gdppc_const_2015_imputed, data = df_imp_hsc_clean, method = "nearest")

# Perform matching
matched_data <- match.data(matchit_object)

# Assess balance
summary(matchit_object)

# Assess balance
summary(matchit_object)

```
```{r}
# Assuming 'matchit_object' is your MatchIt object

# Extract the matched data
matched_data <- match.data(matchit_object)

# View the matched data
head(matched_data)

```

##  Plot response aganist each predicator to exam thier relationship 

```{r}

par(mfrow=c(2, 2))

# Check the response, hsc against each predictor
boxplot(hsc~pepfar,
        main="",
        xlab="PEPFAR support",
        ylab="HSC Index",
        col=blues9,
        data=df_imp_hsc_clean)

# Plot ghsi against income
boxplot(hsc~wb_2022_income_group,
        main="",
        xlab="Income classification",
        ylab=" HSCIndex",
        col=blues9,
        data=df_imp_hsc_clean)


```
There are clear difference in HSC by PEPFAR countries and  income group .

```{r,fig.width = 8, fig.height = 5}
par(mfrow=c(3, 3))

plot(df_imp_hsc_clean$gdppc_const_2015_imputed,
    df_imp_hsc_clean$hsc,
     xlab="gdppc",
     ylab="HSC",
     main="",
     col=gtblue)
abline(lm(hsc~gdppc_const_2015_imputed, data=df_imp_hsc_clean), 
       col=buzzgold, 
       lty=2, lwd=2)

plot(df_imp_hsc_clean$gov_effectiveness_imputed,
     df_imp_hsc_clean$hsc,
     xlab="govet",
     ylab="HSC",
     main="",
     col=gtblue)
abline(lm(hsc~gov_effectiveness_imputed, data=df_imp_hsc_clean), 
       col=buzzgold, 
       lty=2, lwd=2)


 
plot(df_imp_hsc_clean$gghed_imputed,
    df_imp_hsc_clean$hsc,
     xlab="Domestic Gov't exp on health",
     ylab="HSC",
     main="",
     col=gtblue)
abline(lm(hsc~ gghed_imputed, data=df_imp_hsc_clean), 
       col=buzzgold, 
       lty=2, lwd=2)

plot(df_imp_hsc_clean$ext_health_exp_imputed,
    df_imp_hsc_clean$hsc,
     xlab="External Health Expedinature ",
     ylab="HSC",
     main="",
     col=gtblue)
abline(lm(hsc~ext_health_exp_imputed, data=df_imp_hsc_clean), 
       col=buzzgold, 
       lty=2, lwd=2)

plot(df_imp_hsc_clean$pepfar_budget_imputed,
    df_imp_hsc_clean$pepfar_budget_imputed,
     xlab="PEPFAR Funding ",
     ylab="hsc",
     main="",
     col=gtblue)
abline(lm(hsc~pepfar_budget_imputed, data=df_imp_hsc_clean), 
       col=buzzgold, 
       lty=2, lwd=2)


```
There is a positive linear relationship between  HSC & gdppc, hsc and govet, hscand gghe_d. There is not linear relationship between hsc and ext_health  Log-transformation of these predictors may improve the linear relationship

## Plat scatter plot here to assess the linear relation and distribution of predicators

```{r}
library(car)
## hsc vs numeric variables 
scatterplotMatrix(~ hsc +gdppc_const_2015_imputed+gov_effectiveness_imputed+gghed_imputed+pepfar_budget_imputed+ext_health_exp_imputed, data=df_imp_hsc_clean, smooth=FALSE)

```
There is a positive relationship hsc and gdppc, hsc and govet, hsc and gghe_d. However, the distribution of other predicators are skewed. These predictors may need data transformation 

# Correlation between predicators 
```{r}

library(car)
par(mfrow=c(1,1))

# Correlation table
# Select numerical variables
df_num<- na.omit(df_imp_hsc_clean[ , which(sapply(df_imp_hsc_clean, is.numeric))])

# Create correlation matrix
corr <- round(cor(df_num),2)
corr

library(corrplot)

corrplot(
  cor(df_num), method = 'square',type = 'lower',tl.col = 'black',tl.cex = 0.9, col = colorRampPalette(c('purple', 'dark green'))(200)
)

```
There are positive and good correlation between ghsi and gdppc,  ghis&govet, gghe_d and ghsi,  as well as  slight correlation between govet and gdppc, gghe_d and gdppc.



## Fit multilinear regression with all predicators 

```{r}
model1 <- lm(hsc~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+pepfar_budget_imputed+ext_health_exp_imputed, data =matched_data )

summary(model1)
```
The initial model shows pepfar_budget_imputed. income group, gov't effectiveness, gdppc, gghed and net official assi are statistically significant.

## Evaluating model assumptions/ Goodness of Fit


```{r}
# Constant Variance  and uncorrelated errors.

par(mfrow =c(2,2))
library(car)
fits = model1$fitted
resids = rstandard(model1)
plot(fits, resids, xlab="Fitted Values",ylab="Residuals")
abline(0,0,col="red")

#Linearity Assumption

qqPlot(resids, ylab="Residuals", main = "")

hist(resids, xlab="Residuals", main = "",nclass=10,col="orange")

```
The plot shows that residuals uniformly distributed around zero. This hows constant variance and independence slighlty hold. The qq plot and histogram also show normality.

```{r}
variable.names(df_imp_hsc_clean)
```




```{r}
# Check linearity:(Standardized) Residuals versus individual predicting variables -version twp

library(MASS)

par(mfrow =c(2,3))


#plot(df_imp_hsc_clean$gov_effectiveness_imputed,resids,xlab="gov'teff",ylab="Residuals")
#abline(0,0,col="red")



#plot(df_imp_hsc_clean$gdppc_const_2015_imputed,resids,xlab="gdppc",ylab="Residuals")
#abline(0,0,col="red")

#plot(df_imp_hsc_clean$net_official_development_assitance_const_2020_imputed,resids,xlab="net_officail ass",ylab="Residuals")
#abline(0,0,col="red")



#plot(df_imp_hsc_clean$gghed_imputed,resids,xlab="gghed",ylab="Residuals")
#abline(0,0,col="red")


```

Residuals uniformly distributed around zero for ext_health  govet and gghe_d. But there is cluster distribution for other predictors. Log transformation these predictors may improve it.

##Cook’s Distance to check outlier 
```{r}
cook = cooks.distance(model1)
plot(cook,type="h",lwd=3,col="red", ylab = "Cook's Distance")
 #rule of thumb 4/n=4/546=0.04
outlier1 <- which(cook>0.05)
length(outlier1)

```
 it seems that there is one outlier since it close ot 0.04
```{r}
# Check outliers

influencePlot(model1)
plot(cook, type="h", lwd=3, col="blue", ylab="Cook's Distance")

#There is one observation with a Cook’s Distance noticeably higher than the other observations.

```


```{r}
# Multicollinearity 

vif(model1, type = "predictor")


```
 It seems that multicollinearity is not problem since all score is less than 10. However it is good to conduct variable selection since pepfar,and interaction variable's VIF is close 10.


## Assess if the response variable need data transformation 
```{r}
# Box-Cox Transformation
bc = boxCox(model1)
lambda = bc$x[which(bc$y==max(bc$y))]
cat("Optimal lambda:", lambda)

```
Lambda is 0.58 that shows the response variable transformation is not required 

```{r}
# Add a small constant value to handle zero values in pepfar funding (pfunding) before log-transformation 
small_constant <- 0.001  

# Apply log transformation to the predictor column with zero handling
df_imp_hsc_clean$logpfunding<- log(df_imp_hsc_clean$pepfar_budget_imputed + small_constant)
df_imp_hsc_clean$logpfunding= as.numeric(df_imp_hsc_clean$logpfunding)

```

/////////////// Fit full model with log-transformion of predictors//////////

```{r}
colSums(is.na(df_imp_hsc_clean))
```


### log-transformation other predicators that have also skewed distribution  and fit the model2

```{r}
model2 <- lm(hsc~ pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+pepfar_budget_imputed+ext_health_exp_imputed, data =matched_data )
summary(model2)
```
Now govet, gdppc , Europe and central Asia and South Asia are statistically significant 

###  Model 2 -Model assumptions or Good of fit evaluation 


```{r}
### Constant Variance  and uncorrelated errors assumption

par(mfrow =c(2,2))
library(car)
fits2 = model2$fitted
resids2 = rstandard(model2)
plot(fits2, resids2, xlab="Fitted Values",ylab="Residuals")
abline(0,0,col="red")

### Normality Assumption

qqPlot(resids2, ylab="Residuals", main = "")

hist(resids2, xlab="Residuals", main = "",nclass=10,col="orange")

```

Normality and constant variance also hold  and improved here.





##Cook’s Distance to check outlier 
```{r}
cook = cooks.distance(model2)
plot(cook,type="h",lwd=3,col="red", ylab = "Cook's Distance")
 #rule of thumb 4/n=4/80=0.05
outlier2 <- which(cook>0.05)
length(outlier2)

```

We have outliers. We may need to run the final model without it


```{r}
# Box-Cox Transformation
bc = boxCox(model2)
lambda = bc$x[which(bc$y==max(bc$y))]
cat("Optimal lambda:", lambda)

```

Lambda is 0.50 . No need to transform the response variable.


```{r}
vif(model2,  type = "predictor")
```

As VIFs of the netodapc, gdppc, net_offical and gghed are greater than max(10, 1/(1-R2)), it indicates that there is a problem of multicollinearity in the linear model. So, we should not use all the predictors in the model. Let us do variable selection

/////////////////////////////// Variable Selection///////////////////////////////////////////

### Variable selection: Stepwise regression with BIC

```{r}
variable.names(df_imp_hsc_clean)

```


```{r}
set.seed(100)   # for reproducibility 

n = nrow(df_imp_hsc_clean)
# setting the minimum and full model

minimum = lm(hsc~pepfar*time_period,data=df_imp_hsc_clean) # minimum model includes only gdppc since we assume a strong economy relatively lead strong HSC and could be a confounding factor. So it is included in the minimum model
#model2 is full model

#Backward stepwise regression

model_backward <- step(model2, 
     scope = list(lower=minimum, upper = model2), 
     direction = "backward" , k=log(n) , trace=F)

summary(model_backward)

```
Backward stepwise regression selected gdppc, govet, nodar and pepfar are good predictors.

```{r}
# run forward stepwise regression 

set.seed(100)
model_forward <- step(minimum, 
     scope = list(lower=minimum,upper = model2, k=2, trace=FALSE), 
     direction = "forward")
summary(model_forward)
```
Similarly, Forward stepwise regression picked gdppc, govet,pepfar and nodar predictors.


```{r}
# Forward-Backward Stepwise Regression
both.min.model = step(minimum, scope=list(lower=minimum, upper=model2,k=2, trace=FALSE), direction = "both")
summary(both.min.model)
```
Similarly, Forward  and backward stepwise regression picked gdppc, govet,pepfar and nodar predictors.

```{r}
## Obtain Mallow's Cp, AIC, BIC criterion values for stepwise regression
library(CombMSC)
set.seed(41)


## backward 
c(Cp(model_backward,  S2=summary(model_backward)$sigma^2), 
  AIC(model_backward, k=2), AIC(model_backward,k=log(n)))

## forward model
c(Cp(model_forward, S2=summary(model_forward)$sigma^2), 
  AIC(model_forward, k=2), AIC(model_forward,k=log(n)))

#both.min.model
c(Cp(both.min.model, S2=summary(both.min.model)$sigma^2), 
  AIC(both.min.model, k=2), AIC(both.min.model,k=log(n)))

```


```{r}
variable.names(df_imp_hsc_clean)
```




//////////////////////////// Model comparison to pick the best model//////////////////


### Model comparison and performance evaluation using cross-validation  

```{r}
library(caret)
library(modelr)
library(purrr)

set.seed(100)
cv <- crossv_kfold(matched_data, k=10)

 # initial model 
model_cv1 <- map(cv$train,~lm(hsc~pepfar+pepfar*time_period+time_period+pepfar_budget_imputed+wb_2022_income_group+gov_effectiveness_imputed++gdppc_const_2015_imputed+net_official_development_assitance_const_2020_imputed+ext_health_exp_imputed+gghed_imputed, data= .))  

# model with data transformation 
model_cv2 <- map(cv$train,~lm(hsc~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed)+ext_health_exp_imputed+ log(gghed_imputed), data= .)) 

# using variables from backward step wise regression model 

model_cv3 <- map(cv$train,~lm(hsc~pepfar+ time_period + gov_effectiveness_imputed +log(gdppc_const_2015_imputed) +log(net_official_development_assitance_const_2020_imputed) + log(gghed_imputed) + pepfar:time_period, data= .)) 

# # using variables from forward step wise regression model as forward regression

model_cv4 <- map(cv$train,~lm(hsc~ log(gdppc_const_2015_imputed) + pepfar + time_period + gov_effectiveness_imputed + log(gghed_imputed) +log(net_official_development_assitance_const_2020_imputed) + pepfar*time_period, data= .)) 

# back-forward  model

model_cv5 <- map(cv$train,~lm(hsc~ log(gdppc_const_2015_imputed) + pepfar + time_period + gov_effectiveness_imputed + log(gghed_imputed) + log(net_official_development_assitance_const_2020_imputed) + pepfar:time_period, data= .)) 

#  remove log(netodapc_imputed) andext_health_exp_imputed
model_cv6 <- map(cv$train,~lm(hsc~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed), data= .)) 

# remove +log(gdppc_const_2015_imputed) frm above model

model_cv7 <- map(cv$train,~lm(hsc~ pepfar+pepfar*time_period+time_period+wb_2022_income_group+gov_effectiveness_imputed+log(net_official_development_assitance_const_2020_imputed), data= .)) 

# Making predictions on the test data

get_pred  <- function(model, test_data){
  data  <- as.data.frame(test_data)
  pred  <- add_predictions(data, model)
  return(pred)
}
pred1  <- map2_df(model_cv1, cv$test, get_pred, .id = "Run")
pred2  <- map2_df(model_cv2, cv$test, get_pred, .id = "Run")
pred3  <- map2_df(model_cv3, cv$test, get_pred, .id = "Run")
pred4  <- map2_df(model_cv4, cv$test, get_pred, .id = "Run")
pred5  <- map2_df(model_cv5, cv$test, get_pred, .id = "Run")
pred6  <- map2_df(model_cv6, cv$test, get_pred, .id = "Run")
pred7  <- map2_df(model_cv7, cv$test, get_pred, .id = "Run")



# Calculating Mean Squared Error (MSE)
MSE1  <- pred1 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE2  <- pred2 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE3  <- pred3 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE4  <- pred4 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE5  <- pred5 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE6  <- pred6 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))
MSE7  <- pred7 %>% group_by(Run) %>%
  summarise(MSE = mean( (hsc - pred)^2))

MSE_min <- c(MSE1_min <- mean(MSE1$MSE),
MSE2_min <-mean(MSE2$MSE),
MSE3_min <-mean(MSE3$MSE),
MSE4_min <-mean(MSE4$MSE),
MSE5_min <-mean(MSE5$MSE),
MSE6_min <-mean(MSE6$MSE),
MSE7_min <-mean(MSE7$MSE)
)



# Calculating Root Mean Squared Error (RMSE)
RMSE <- c(RMSE1 <- sqrt(MSE1_min), RMSE2<- sqrt(MSE2_min), RMSE3<- sqrt(MSE3_min), RMSE4<- sqrt(MSE4_min), RMSE5<- sqrt(MSE5_min), RMSE6<- sqrt(MSE6_min), RMSE7<- sqrt(MSE7_min))

# Calculating Mean Absolute Error (MAE)

MAE1  <- pred1 %>% group_by(Run) %>%
  summarise(MAE = mean(abs (hsc - pred)))
MAE2  <- pred2 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc - pred)))
MAE3  <- pred3 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc - pred)))
MAE4  <- pred4 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc - pred)))
MAE5  <- pred5 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc- pred)))
MAE6  <- pred6 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc - pred)))
MAE7  <- pred7 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(hsc - pred)))

MAE_min <- c(MAE1_min <- mean(MAE1$MAE),
MAE2_min <-mean(MAE2$MAE),
MAE3_min <-mean(MAE3$MAE),
MAE4_min <-mean(MAE4$MAE),
MAE5_min <-mean(MAE5$MAE),
MAE6_min <-mean(MAE6$MAE),
MSE7_min <-mean(MAE7$MAE)
)

# Calculate R-squared

r_squared1  <- pred1 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc,pred)^2)
r_squared2 <- pred2 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc, pred)^2)
r_squared3 <- pred3 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc, pred)^2)
r_squared4 <- pred4 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc, pred)^2)
r_squared5 <- pred5 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc,pred)^2)
r_squared6 <- pred6 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc,pred)^2)
r_squared7 <- pred7 %>% group_by(Run) %>%
  summarise(rsq= cor(hsc,pred)^2)

R_Squared <- c(r_squared1_avg <- mean(r_squared1$rsq),
r_squared2_avg  <-mean(r_squared2$rsq),
r_squared3_avg  <-mean(r_squared3$rsq),
r_squared4_avg <-mean(r_squared4$rsq),
r_squared5_avg <-mean(r_squared5$rsq),
r_squared6_avg <-mean(r_squared6$rsq),
r_squared7_avg  <-mean(r_squared7$rsq)
)


models_cv<- c("model_cv1","model_cv2", "model_cv3","model_cv4","model_cv5", "model_cv6","model_cv7")
 model_comp_cv <- data.frame(models_cv,MSE_min,RMSE,MAE_min, R_Squared)
model_comp_cv


```

all models perform similarly. Initial model has slightly higher R-squared and lowest RMSE. so we need to decide what predictors we should use 


# comparing the models using adj-r-squa
```{r}
 # final model 
model_final <-lm(hsc~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed)+ext_health_exp_imputed, data=matched_data) 

summary(model_final)
```

******************** fitting the final model with HSC-sub index **********************************


```{r}
variable.names(df_imp)
```



```{r}
df_imp_id <- df_imp[-c(4,5,6,7,8,11,13,14)]
variable.names(df_imp_id)

df_imp_id_clean <- df_imp_id[complete.cases(df_imp_id), ]

colSums(is.na(df_imp_id_clean))

# Propensity Score Matching (PSM) is a method to create comparable countries 

# Load the MatchIt package

library(MatchIt)

# Assuming 'data' is your dataset and 'treatment' is the treatment indicator variable
model_ps2 <- glm(pepfar ~ gov_effectiveness_imputed+ gghed_imputed+gdppc_const_2015_imputed, data = df_imp_id_clean, family = "binomial")

propensity_scores <- predict(model_ps, type = "response")

# Create a MatchIt object
matchit_object2 <- matchit(pepfar ~ gov_effectiveness_imputed+ gghed_imputed+gdppc_const_2015_imputed, data = df_imp_id_clean, method = "nearest")

# Perform matching
matched_data2 <- match.data(matchit_object2)

# Assess balance
summary(matchit_object2)

# Assess balance
summary(matchit_object2)

```



```{r}
 # final model for ID
model_final_id <- lm(id~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed)+ext_health_exp_imputed, data=matched_data2) 


summary(model_final_id)


```

### Model comparison and performance evaluation using cross-validation  

```{r}
library(caret)
library(modelr)
library(purrr)

set.seed(100)
cv <- crossv_kfold(matched_data2, k=10)

 # initial model 
model_cv11 <- map(cv$train,~lm(id~pepfar+pepfar*time_period+time_period+pepfar_budget_imputed+wb_2022_income_group+gov_effectiveness_imputed++gdppc_const_2015_imputed+net_official_development_assitance_const_2020_imputed+ext_health_exp_imputed+gghed_imputed, data= .))  

# model with data transformation 
model_cv22 <- map(cv$train,~lm(id~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed)+ext_health_exp_imputed+ log(gghed_imputed), data= .)) 

# using variables from backward step wise regression model 

model_cv33 <- map(cv$train,~lm(id~pepfar+ time_period + gov_effectiveness_imputed +log(gdppc_const_2015_imputed) +log(net_official_development_assitance_const_2020_imputed) + log(gghed_imputed) + pepfar:time_period, data= .)) 

# # using variables from forward step wise regression model as forward regression

model_cv44 <- map(cv$train,~lm(id~ log(gdppc_const_2015_imputed) + pepfar + time_period + gov_effectiveness_imputed + log(gghed_imputed) +log(net_official_development_assitance_const_2020_imputed) + pepfar*time_period, data= .)) 

# back-forward  model

model_cv55 <- map(cv$train,~lm(id~ log(gdppc_const_2015_imputed) + pepfar + time_period + gov_effectiveness_imputed + log(gghed_imputed) + log(net_official_development_assitance_const_2020_imputed) + pepfar:time_period, data= .)) 

#  remove log(netodapc_imputed) andext_health_exp_imputed
model_cv66 <- map(cv$train,~lm(id~pepfar+pepfar*time_period+time_period+gov_effectiveness_imputed+log(gdppc_const_2015_imputed)+log(net_official_development_assitance_const_2020_imputed), data= .)) 

# remove +log(gdppc_const_2015_imputed) frm above model

model_cv77 <- map(cv$train,~lm(id~ pepfar+pepfar*time_period+time_period+wb_2022_income_group+gov_effectiveness_imputed+log(net_official_development_assitance_const_2020_imputed), data= .)) 

# Making predictions on the test data

get_pred  <- function(model, test_data){
  data  <- as.data.frame(test_data)
  pred  <- add_predictions(data, model)
  return(pred)
}
pred1  <- map2_df(model_cv1, cv$test, get_pred, .id = "Run")
pred2  <- map2_df(model_cv2, cv$test, get_pred, .id = "Run")
pred3  <- map2_df(model_cv3, cv$test, get_pred, .id = "Run")
pred4  <- map2_df(model_cv4, cv$test, get_pred, .id = "Run")
pred5  <- map2_df(model_cv5, cv$test, get_pred, .id = "Run")
pred6  <- map2_df(model_cv6, cv$test, get_pred, .id = "Run")
pred7  <- map2_df(model_cv7, cv$test, get_pred, .id = "Run")



# Calculating Mean Squared Error (MSE)
MSE1  <- pred1 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE2  <- pred2 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE3  <- pred3 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE4  <- pred4 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE5  <- pred5 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE6  <- pred6 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))
MSE7  <- pred7 %>% group_by(Run) %>%
  summarise(MSE = mean( (id - pred)^2))

MSE_min <- c(MSE1_min <- mean(MSE1$MSE),
MSE2_min <-mean(MSE2$MSE),
MSE3_min <-mean(MSE3$MSE),
MSE4_min <-mean(MSE4$MSE),
MSE5_min <-mean(MSE5$MSE),
MSE6_min <-mean(MSE6$MSE),
MSE7_min <-mean(MSE7$MSE)
)



# Calculating Root Mean Squared Error (RMSE)
RMSE <- c(RMSE1 <- sqrt(MSE1_min), RMSE2<- sqrt(MSE2_min), RMSE3<- sqrt(MSE3_min), RMSE4<- sqrt(MSE4_min), RMSE5<- sqrt(MSE5_min), RMSE6<- sqrt(MSE6_min), RMSE7<- sqrt(MSE7_min))

# Calculating Mean Absolute Error (MAE)

MAE1  <- pred1 %>% group_by(Run) %>%
  summarise(MAE = mean(abs (id - pred)))
MAE2  <- pred2 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id - pred)))
MAE3  <- pred3 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id - pred)))
MAE4  <- pred4 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id - pred)))
MAE5  <- pred5 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id- pred)))
MAE6  <- pred6 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id - pred)))
MAE7  <- pred7 %>% group_by(Run) %>%
  summarise(MAE = mean( abs(id - pred)))

MAE_min <- c(MAE1_min <- mean(MAE1$MAE),
MAE2_min <-mean(MAE2$MAE),
MAE3_min <-mean(MAE3$MAE),
MAE4_min <-mean(MAE4$MAE),
MAE5_min <-mean(MAE5$MAE),
MAE6_min <-mean(MAE6$MAE),
MSE7_min <-mean(MAE7$MAE)
)

# Calculate R-squared

r_squared1  <- pred1 %>% group_by(Run) %>%
  summarise(rsq= cor(id,pred)^2)
r_squared2 <- pred2 %>% group_by(Run) %>%
  summarise(rsq= cor(id, pred)^2)
r_squared3 <- pred3 %>% group_by(Run) %>%
  summarise(rsq= cor(id, pred)^2)
r_squared4 <- pred4 %>% group_by(Run) %>%
  summarise(rsq= cor(id, pred)^2)
r_squared5 <- pred5 %>% group_by(Run) %>%
  summarise(rsq= cor(id,pred)^2)
r_squared6 <- pred6 %>% group_by(Run) %>%
  summarise(rsq= cor(id,pred)^2)
r_squared7 <- pred7 %>% group_by(Run) %>%
  summarise(rsq= cor(id,pred)^2)

R_Squared <- c(r_squared1_avg <- mean(r_squared1$rsq),
r_squared2_avg  <-mean(r_squared2$rsq),
r_squared3_avg  <-mean(r_squared3$rsq),
r_squared4_avg <-mean(r_squared4$rsq),
r_squared5_avg <-mean(r_squared5$rsq),
r_squared6_avg <-mean(r_squared6$rsq),
r_squared7_avg  <-mean(r_squared7$rsq)
)


models_cv<- c("model_cv11","model_cv2", "model_cv33","model_cv44","model_cv55", "model_cv66","model_cv77")
 model_comp_cv1 <- data.frame(models_cv,MSE_min,RMSE,MAE_min, R_Squared)
model_comp_cv1


`````
